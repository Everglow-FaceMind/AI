{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "from models import LinkNet34\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LinkNet34()\n",
    "# model.load_state_dict(torch.load('linknet.pth'))\n",
    "model.load_state_dict(torch.load('linknet.pth', map_location=lambda storage, loc: storage))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 감지 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection = mp_face_detection.FaceDetection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV를 사용하여 비디오 스트림을 캡처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)  # 웹캠 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼굴 감지 및 segmentation(모델 사용 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # 프레임을 RGB로 변환\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 얼굴 감지 수행\n",
    "    results = face_detection.process(frame_rgb)\n",
    "    \n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            ih, iw, _ = frame.shape\n",
    "            x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "            roi = frame[y:y+h, x:x+w]  # ROI 추출\n",
    "\n",
    "            roifilename = \"roi_img.jpg\"\n",
    "            cv2.imwrite(roifilename, roi)\n",
    "            \n",
    "            # ROI를 HSV 색상 공간으로 변환\n",
    "            roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # 피부 색상에 대한 범위 설정 (이 범위는 적절히 조정될 수 있습니다)\n",
    "            lower_skin = np.array([0, 48, 80], dtype=np.uint8)\n",
    "            upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "\n",
    "            # 피부 영역을 마스크로 만듭니다\n",
    "            skin_mask = cv2.inRange(roi_hsv, lower_skin, upper_skin)\n",
    "\n",
    "            # 피부 영역만 남기고 나머지는 검정색으로 처리\n",
    "            skin_segmentation = cv2.bitwise_and(roi, roi, mask=skin_mask)\n",
    "\n",
    "            # 세그멘테이션된 이미지를 원래 크기로 조정\n",
    "            segmentation_resized = cv2.resize(skin_segmentation, (w, h))\n",
    "\n",
    "            # 원본 프레임에 세그멘테이션된 영역을 추가합니다\n",
    "            frame[y:y+h, x:x+w] = segmentation_resized\n",
    "    \n",
    "    # 화면에 출력\n",
    "    cv2.imshow('Face Segmentation', frame)\n",
    "\n",
    "    # 's' 키를 누르면 세그멘테이션된 ROI를 저장합니다.\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('s'):\n",
    "        filename = \"segmented_roi.jpg\"\n",
    "        cv2.imwrite(filename, segmentation_resized)\n",
    "        print(\"Segmented ROI saved as\", filename)\n",
    "    \n",
    "    # 'q' 키를 누르면 종료\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# 종료\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3420\\3957546450.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'segmented_roi.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('segmented_roi.jpg', cv2.IMREAD_COLOR)\n",
    "cv2.imshow('img', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation(deep learning 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'wcwidth'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# MediaPipe 얼굴 감지 초기화\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "\n",
    "# 모델 로드 (사전에 학습된 LinkNet34 모델을 로드하는 코드를 추가하세요)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LinkNet34()\n",
    "# model.load_state_dict(torch.load('linknet.pth'))\n",
    "model.load_state_dict(torch.load('linknet.pth', map_location=lambda storage, loc: storage))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "face_counter = 0\n",
    "# 비디오 캡처 초기화\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # 프레임을 RGB로 변환하여 얼굴 감지 수행\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(frame_rgb)\n",
    "    \n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            # 감지된 얼굴 영역 추출\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            ih, iw, _ = frame.shape\n",
    "            x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            roi_filename = f\"roi_face_{face_counter}_{int(time.time())}.jpg\"\n",
    "            cv2.imwrite(roi_filename, roi)\n",
    "            \n",
    "            # 분할 모델을 위한 전처리\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((256, 256)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "            roi_tensor = transform(roi).unsqueeze(0) # 모델 입력을 위한 텐서\n",
    "\n",
    "            # 모델 적용 및 분할 마스크 생성ㅂㅂㅂ\n",
    "            with torch.no_grad():\n",
    "                mask_pred = model(roi_tensor)\n",
    "                mask = mask_pred.squeeze().cpu().numpy()\n",
    "                mask = (mask > 0.5).astype(np.uint8)  # 마스크를 uint8 타입으로 변환\n",
    "\n",
    "            # 분할 결과 적용: 피부를 제외한 나머지 부분을 검은색으로 처리\n",
    "            mask_resized = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "            full_mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "            full_mask[y:y+h, x:x+w] = mask_resized\n",
    "            frame[full_mask == 0] = [0, 0, 0]\n",
    "\n",
    "            # 분할된 영역 이미지 파일로 저장\n",
    "            segmented_face = np.zeros_like(roi)  # 분할된 얼굴 영역에 대한 빈 이미지 생성\n",
    "            for c in range(3):  # 채널별로 마스크 적용\n",
    "                segmented_face[:, :, c] = roi[:, :, c] * mask_resized\n",
    "            \n",
    "            \n",
    "\n",
    "            # 분할된 얼굴 영역을 이미지 파일로 저장\n",
    "            face_filename = f\"segmented_face_{face_counter}_{int(time.time())}.jpg\"\n",
    "            cv2.imwrite(face_filename, segmented_face)\n",
    "            print(f\"Segmented face saved as {face_filename}\")\n",
    "            face_counter += 1\n",
    "\n",
    "    cv2.imshow('Segmentation', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'wcwidth'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "roi_img = cv2.imread('roi_face_46_1711608704.jpg', cv2.IMREAD_COLOR)\n",
    "roi_img_rgb = cv2.cvtColor(roi_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "seg_img = cv2.imread('segmented_face_45_1711608704.jpg', cv2.IMREAD_COLOR)\n",
    "seg_img_rgb = cv2.cvtColor(seg_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(10, 5))  \n",
    "\n",
    "plt.subplot(1, 2, 1)  \n",
    "plt.imshow(roi_img_rgb)\n",
    "plt.title('Original ROI')  \n",
    "plt.axis('off')  \n",
    "\n",
    "plt.subplot(1, 2, 2)  \n",
    "plt.imshow(seg_img_rgb)\n",
    "plt.title('Segmented Face')  \n",
    "plt.axis('off')  \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
